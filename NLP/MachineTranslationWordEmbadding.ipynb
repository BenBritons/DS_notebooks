{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BenBritons/DS_notebooks/blob/main/NLP/MachineTranslationWordEmbadding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjhdj64qD6ub"
      },
      "source": [
        "##Multilingual Embedding-based Machine Translation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9QznOoGD6ug"
      },
      "source": [
        "**In this notebook** **<font color='red'>I</font>** will make machine translation system without using parallel corpora, alignment, attention, 100500 depth super-cool recurrent neural network and all that kind superstuff.\n",
        "\n",
        "But even without parallel corpora this system can be good enough (hopefully).\n",
        "\n",
        "For our system we choose two kindred Slavic languages: Ukranian and Russian."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR5nSb4tD6uh"
      },
      "source": [
        "### Feel the difference!\n",
        "\n",
        "(_синій кіт_ vs. _синій кит_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiIaAE-PD6uj"
      },
      "source": [
        "![blue_cat_blue_whale.png](https://github.com/yandexdataschool/nlp_course/raw/master/resources/blue_cat_blue_whale.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzygjKdvD6uj"
      },
      "source": [
        "### Frament of the Swadesh list for some slavic languages\n",
        "\n",
        "The Swadesh list is a lexicostatistical stuff. It's named after American linguist Morris Swadesh and contains basic lexis. This list are used to define subgroupings of languages, its relatedness.\n",
        "\n",
        "So we can see some kind of word invariance for different Slavic languages.\n",
        "\n",
        "\n",
        "| Russian         | Belorussian              | Ukrainian               | Polish             | Czech                         | Bulgarian            |\n",
        "|-----------------|--------------------------|-------------------------|--------------------|-------------------------------|-----------------------|\n",
        "| женщина         | жанчына, кабета, баба    | жінка                   | kobieta            | žena                          | жена                  |\n",
        "| мужчина         | мужчына                  | чоловік, мужчина        | mężczyzna          | muž                           | мъж                   |\n",
        "| человек         | чалавек                  | людина, чоловік         | człowiek           | člověk                        | човек                 |\n",
        "| ребёнок, дитя   | дзіця, дзіцёнак, немаўля | дитина, дитя            | dziecko            | dítě                          | дете                  |\n",
        "| жена            | жонка                    | дружина, жінка          | żona               | žena, manželka, choť          | съпруга, жена         |\n",
        "| муж             | муж, гаспадар            | чоловiк, муж            | mąż                | muž, manžel, choť             | съпруг, мъж           |\n",
        "| мать, мама      | маці, матка              | мати, матір, неня, мама | matka              | matka, máma, 'стар.' mateř    | майка                 |\n",
        "| отец, тятя      | бацька, тата             | батько, тато, татусь    | ojciec             | otec                          | баща, татко           |\n",
        "| много           | шмат, багата             | багато                  | wiele              | mnoho, hodně                  | много                 |\n",
        "| несколько       | некалькі, колькі         | декілька, кілька        | kilka              | několik, pár, trocha          | няколко               |\n",
        "| другой, иной    | іншы                     | інший                   | inny               | druhý, jiný                   | друг                  |\n",
        "| зверь, животное | жывёла, звер, істота     | тварина, звір           | zwierzę            | zvíře                         | животно               |\n",
        "| рыба            | рыба                     | риба                    | ryba               | ryba                          | риба                  |\n",
        "| птица           | птушка                   | птах, птиця             | ptak               | pták                          | птица                 |\n",
        "| собака, пёс     | сабака                   | собака, пес             | pies               | pes                           | куче, пес             |\n",
        "| вошь            | вош                      | воша                    | wesz               | veš                           | въшка                 |\n",
        "| змея, гад       | змяя                     | змія, гад               | wąż                | had                           | змия                  |\n",
        "| червь, червяк   | чарвяк                   | хробак, черв'як         | robak              | červ                          | червей                |\n",
        "| дерево          | дрэва                    | дерево                  | drzewo             | strom, dřevo                  | дърво                 |\n",
        "| лес             | лес                      | ліс                     | las                | les                           | гора, лес             |\n",
        "| палка           | кій, палка               | палиця                  | patyk, pręt, pałka | hůl, klacek, prut, kůl, pálka | палка, пръчка, бастун |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBKla_91D6ul"
      },
      "source": [
        "But the context distribution of these languages demonstrates even more invariance. And we can use this fact for our for our purposes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xxl_Gje1D6um"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "A23gVcMZD6un"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAcV5PSCD6up"
      },
      "source": [
        "Download embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F12loXcYFlCy",
        "outputId": "c4e65c32-be44-4dbe-c1cd-21ea9f16dc92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1245M  100 1245M    0     0  19.3M      0  0:01:04  0:01:04 --:--:-- 20.7M\n"
          ]
        }
      ],
      "source": [
        "!curl -o cc.ru.300.vec.gz https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
        "!gunzip cc.ru.300.vec.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hQdhavsFvsz",
        "outputId": "2652ecae-17c9-4a6d-a4d5-ebaf20749841"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1199M  100 1199M    0     0  19.4M      0  0:01:01  0:01:01 --:--:-- 22.9M\n"
          ]
        }
      ],
      "source": [
        "!curl -o cc.uk.300.vec.gz https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.uk.300.vec.gz\n",
        "!gunzip cc.uk.300.vec.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "T1lVPcx_JdMJ"
      },
      "outputs": [],
      "source": [
        "#!pip install fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vEDjNdb6MlXe"
      },
      "outputs": [],
      "source": [
        "#!pip install gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tRB4UfxD6uq"
      },
      "source": [
        "\n",
        "Load embeddings for ukranian and russian."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CK4ru2DED6uq"
      },
      "outputs": [],
      "source": [
        "uk_emb = KeyedVectors.load_word2vec_format(\"cc.uk.300.vec\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(uk_emb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLmQvhVNUv00",
        "outputId": "fd07bbf0-a216-4dbb-b0f2-387dfa102fd9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000000"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cShvEdtJD6ur"
      },
      "outputs": [],
      "source": [
        "ru_emb = KeyedVectors.load_word2vec_format('cc.ru.300.vec')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLT142v4D6ur",
        "outputId": "a55f5894-ff58-4af3-9df3-5f9d0c442a34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('дом', 1.0),\n",
              " ('особняк', 0.7073208689689636),\n",
              " ('коттедж', 0.697927713394165),\n",
              " ('домик', 0.6890208125114441),\n",
              " ('Дом', 0.6677538752555847),\n",
              " ('дом.В', 0.6623372435569763),\n",
              " ('дом.А', 0.6590256094932556),\n",
              " ('дом-', 0.6414237022399902),\n",
              " ('загородный', 0.6390586495399475),\n",
              " ('офис', 0.6238341331481934)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "ru_emb.most_similar([ru_emb[\"дом\"]], topn=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XECihdn2D6ur",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f68c56d4-5e5f-41f8-bd5d-f6469935884c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('хата', 1.0000001192092896),\n",
              " ('хата-', 0.7466036677360535),\n",
              " ('хатка', 0.6733182668685913),\n",
              " ('хатина', 0.6623023152351379),\n",
              " ('хатинка', 0.6520452499389648),\n",
              " ('хата-мазанка', 0.64560467004776),\n",
              " ('reakcji', 0.6153016686439514),\n",
              " ('оселя', 0.6063539385795593),\n",
              " ('курна', 0.60240638256073),\n",
              " ('Хата', 0.5938948392868042)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "uk_emb.most_similar([uk_emb[\"хата\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nLAl8cbpD6ur",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51cadc2b-f09d-4b1e-9050-3f0fe6f5b36d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('-Александр', 0.2608003318309784),\n",
              " ('сopeвнoваниях', 0.2597772479057312),\n",
              " ('подрядиться', 0.259461373090744),\n",
              " ('дрожках', 0.25474271178245544),\n",
              " ('плясун', 0.25230672955513),\n",
              " ('Фёдорыч', 0.24858714640140533),\n",
              " ('вызвалась', 0.2417260855436325),\n",
              " ('Гедеван', 0.2410685271024704),\n",
              " ('Лихов', 0.23922650516033173),\n",
              " ('Тёркин', 0.23871248960494995)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "ru_emb.most_similar([uk_emb[\"хата\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3r7F7pDD6us"
      },
      "source": [
        "Load small dictionaries for correspoinding words pairs as trainset and testset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Leav8nR3D6us"
      },
      "outputs": [],
      "source": [
        "def load_word_pairs(filename):\n",
        "    uk_ru_pairs = []\n",
        "    uk_vectors = []\n",
        "    ru_vectors = []\n",
        "    with open(filename, \"r\") as inpf:\n",
        "        for line in inpf:\n",
        "            uk, ru = line.rstrip().split(\"\\t\")\n",
        "            if uk not in uk_emb or ru not in ru_emb:\n",
        "                continue\n",
        "            uk_ru_pairs.append((uk, ru))\n",
        "            uk_vectors.append(uk_emb[uk])\n",
        "            ru_vectors.append(ru_emb[ru])\n",
        "    return uk_ru_pairs, np.array(uk_vectors), np.array(ru_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-ecPpQCsD6us"
      },
      "outputs": [],
      "source": [
        "uk_ru_train, X_train, Y_train = load_word_pairs(\"ukr_rus.train.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "H2uh-id9D6us"
      },
      "outputs": [],
      "source": [
        "uk_ru_test, X_test, Y_test = load_word_pairs(\"ukr_rus.test.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHOHDVjwD6ut"
      },
      "source": [
        "## Embedding space mapping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3u3LWvSMD6ut"
      },
      "source": [
        "Let $x_i \\in \\mathrm{R}^d$ be the distributed representation of word $i$ in the source language, and $y_i \\in \\mathrm{R}^d$ is the vector representation of its translation. Our purpose is to learn such linear transform $W$ that minimizes euclidian distance between $Wx_i$ and $y_i$ for some subset of word embeddings. Thus we can formulate so-called Procrustes problem:\n",
        "\n",
        "$$W^*= \\arg\\min_W \\sum_{i=1}^n||Wx_i - y_i||_2$$\n",
        "or\n",
        "$$W^*= \\arg\\min_W ||WX - Y||_F$$\n",
        "\n",
        "where $||*||_F$ - Frobenius norm.\n",
        "\n",
        "In Greek mythology, Procrustes or \"the stretcher\" was a rogue smith and bandit from Attica who attacked people by stretching them or cutting off their legs, so as to force them to fit the size of an iron bed. We make same bad things with source embedding space. Our Procrustean bed is target embedding space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIy5EOGwD6ut"
      },
      "source": [
        "![embedding_mapping.png](https://github.com/yandexdataschool/nlp_course/raw/master/resources/embedding_mapping.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKbq6U12D6uu"
      },
      "source": [
        "![procrustes.png](https://github.com/yandexdataschool/nlp_course/raw/master/resources/procrustes.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_sWZPIED6uu"
      },
      "source": [
        "But wait...$W^*= \\arg\\min_W \\sum_{i=1}^n||Wx_i - y_i||_2$ looks like simple multiple linear regression (without intercept fit). So let's code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "fWud7p5qD6uu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "cfae2b8a-7db9-42a5-e29c-8344c7c806e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr.score(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hk94Tdh9yyL",
        "outputId": "f1ffa1dd-0059-48bc-d200-910fb639614a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5387453182044396"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehDcRH4FD6uu"
      },
      "source": [
        "Let's take a look at neigbours of the vector of word _\"серпень\"_ (_\"август\"_ in Russian) after linear transform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ukYcPO-MD6uv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a82b5f05-6975-422f-deed-bf7dec3131ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('апрель', 0.8531403541564941),\n",
              " ('июнь', 0.8402307629585266),\n",
              " ('март', 0.8385774493217468),\n",
              " ('сентябрь', 0.8331867456436157),\n",
              " ('февраль', 0.8311492800712585),\n",
              " ('октябрь', 0.8278172016143799),\n",
              " ('ноябрь', 0.8244150876998901),\n",
              " ('июль', 0.8228995203971863),\n",
              " ('август', 0.8112361431121826),\n",
              " ('январь', 0.8022859692573547)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "august = lr.predict(uk_emb[\"серпень\"].reshape(1, -1))\n",
        "ru_emb.most_similar(august)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ru_emb.most_similar(lr.predict(uk_emb['серпень'].reshape(1, -1)), topn = 9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAqDtwxM_19B",
        "outputId": "b0cd2a04-1f88-4b58-c5d3-f0a21a3a7d6d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('апрель', 0.8531403541564941)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-86lDhjYD6uv"
      },
      "source": [
        "We can see that neighbourhood of this embedding cosists of different months, but right variant is on the ninth place."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEFzD7GDD6uv"
      },
      "source": [
        "As quality measure we will use precision top-1, top-5 and top-10 (for each transformed Ukrainian embedding we count how many right target pairs are found in top N nearest neighbours in Russian embedding space)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "BWPR-ZO7D6uv"
      },
      "outputs": [],
      "source": [
        "def precision(pairs, mapped_vectors, topn=1):\n",
        "    \"\"\"\n",
        "    :args:\n",
        "        pairs = list of right word pairs [(uk_word_0, ru_word_0), ...]\n",
        "        mapped_vectors = list of embeddings after mapping from source embedding space to destination embedding space\n",
        "        topn = the number of nearest neighbours in destination embedding space to choose from\n",
        "    :returns:\n",
        "        precision_val, float number, total number of words for those we can find right translation at top K.\n",
        "    \"\"\"\n",
        "    assert len(pairs) == len(mapped_vectors)\n",
        "    num_matches = 0\n",
        "    for i, (_, ru) in enumerate(pairs):\n",
        "      for j in ru_emb.most_similar(lr.predict(uk_emb[_].reshape(1, -1)), topn = topn):\n",
        "        if ru in j:\n",
        "          num_matches += 1\n",
        "    precision_val = num_matches / len(pairs)\n",
        "    return precision_val\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision([(\"серпень\", \"август\")], august, topn=9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSMt0idK_pj4",
        "outputId": "c1807984-1a7d-462e-823e-7c69db998aec"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "R1PJMqC_D6uw"
      },
      "outputs": [],
      "source": [
        "assert precision([(\"серпень\", \"август\")], august, topn=5) == 0.0\n",
        "assert precision([(\"серпень\", \"август\")], august, topn=9) == 1.0\n",
        "assert precision([(\"серпень\", \"август\")], august, topn=10) == 1.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(precision(uk_ru_test, X_test))\n",
        "print(precision(uk_ru_test, Y_test))\n",
        "print(precision(uk_ru_test, lr.predict(X_test), 1))\n",
        "print(precision(uk_ru_test, lr.predict(X_test), 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHntSF5HCoZu",
        "outputId": "d70f3ffd-eb08-404d-d73c-dc2831bcf72e"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6259541984732825\n",
            "0.6259541984732825\n",
            "0.6259541984732825\n",
            "0.7913486005089059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "-Ic6qC93D6uw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "bb70d191-806b-4094-d979-21c412434c09"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-175315edcf0d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#assert precision(uk_ru_test, X_test) == 0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muk_ru_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "assert precision(uk_ru_test, X_test) == 0.0\n",
        "assert precision(uk_ru_test, Y_test) == 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "eUJRVTC7D6uw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "116d8ba4-a4d8-4390-c178-0041e62c179a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-b062d80fbddb>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprecision_top5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muk_ru_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mprecision_top1\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.635\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mprecision_top5\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.813\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "precision_top1 = precision(uk_ru_test, lr.predict(X_test), 1)\n",
        "precision_top5 = precision(uk_ru_test, lr.predict(X_test), 5)\n",
        "\n",
        "assert precision_top1 >= 0.635\n",
        "assert precision_top5 >= 0.813"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6_2LMNSD6ux"
      },
      "source": [
        "## Making it better (orthogonal Procrustean problem)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z8HTl4xD6ux"
      },
      "source": [
        "It can be shown (see original paper) that a self-consistent linear mapping between semantic spaces should be orthogonal.\n",
        "We can restrict transform $W$ to be orthogonal. Then we will solve next problem:\n",
        "\n",
        "$$W^*= \\arg\\min_W ||WX - Y||_F \\text{, where: } W^TW = I$$\n",
        "\n",
        "$$I \\text{- identity matrix}$$\n",
        "\n",
        "Instead of making yet another regression problem we can find optimal orthogonal transformation using singular value decomposition. It turns out that optimal transformation $W^*$ can be expressed via SVD components:\n",
        "$$X^TY=U\\Sigma V^T\\text{, singular value decompostion}$$\n",
        "$$W^*=UV^T$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "SnSUYU9UD6ux"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def learn_transform(X_train, Y_train):\n",
        "    \"\"\"\n",
        "    :returns: W* : float matrix[emb_dim x emb_dim] as defined in formulae above\n",
        "    \"\"\"\n",
        "    X = np.array(X_train)\n",
        "    Y = np.array(Y_train)\n",
        "    U, W, Vh = np.linalg.svd(np.transpose(X) @ Y)\n",
        "\n",
        "    return U @ Vh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "cOQ-bTanD6ux"
      },
      "outputs": [],
      "source": [
        "W = learn_transform(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taqLon0LGbxg",
        "outputId": "197c34be-144d-4354-8888-8b69e2dd236d"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.0000002e+00, -1.0445934e-08,  8.2780481e-08, ...,\n",
              "         1.0242603e-08, -7.0971784e-09, -2.1691626e-08],\n",
              "       [-1.0445934e-08,  9.9999982e-01,  1.0376747e-08, ...,\n",
              "         2.3747004e-08,  1.9949768e-08, -1.1788722e-08],\n",
              "       [ 8.2780481e-08,  1.0376747e-08,  9.9999970e-01, ...,\n",
              "         6.7716904e-08,  2.8304335e-08, -4.4140510e-08],\n",
              "       ...,\n",
              "       [ 1.0242603e-08,  2.3747004e-08,  6.7716904e-08, ...,\n",
              "         9.9999946e-01, -1.6319246e-08, -3.4254217e-08],\n",
              "       [-7.0971784e-09,  1.9949768e-08,  2.8304335e-08, ...,\n",
              "        -1.6319246e-08,  9.9999982e-01, -9.6067403e-09],\n",
              "       [-2.1691626e-08, -1.1788722e-08, -4.4140510e-08, ...,\n",
              "        -3.4254217e-08, -9.6067403e-09,  1.0000001e+00]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "sT-AuKphD6ux",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f870ae86-a17b-400d-d191-d268fef731ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('апрель', 0.8245132565498352),\n",
              " ('июнь', 0.8056628704071045),\n",
              " ('сентябрь', 0.8055762648582458),\n",
              " ('март', 0.8032935261726379),\n",
              " ('октябрь', 0.798710286617279),\n",
              " ('июль', 0.794679582118988),\n",
              " ('ноябрь', 0.7939637899398804),\n",
              " ('август', 0.7938188314437866),\n",
              " ('февраль', 0.7923861742019653),\n",
              " ('декабрь', 0.7715376019477844)]"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "ru_emb.most_similar([np.matmul(uk_emb[\"серпень\"], W)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "o239Q9HVD6uy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41f186c2-bbbb-41da-f9a3-5c51e539019c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6259541984732825\n",
            "0.7913486005089059\n"
          ]
        }
      ],
      "source": [
        "print(precision(uk_ru_test, np.matmul(X_test, W)))\n",
        "print(precision(uk_ru_test, np.matmul(X_test, W), 5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vpCvfejD6uz"
      },
      "source": [
        "## UK-RU Translator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtNiUEgjD6u0"
      },
      "source": [
        "Now we are ready to make simple word-based translator: for earch word in source language in shared embedding space we find the nearest in target language.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUsvO7y0D6u0"
      },
      "outputs": [],
      "source": [
        "with open(\"fairy_tale.txt\", \"r\") as inpf:\n",
        "    uk_sentences = [line.rstrip().lower() for line in inpf]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "FygcyG2BD6u0"
      },
      "outputs": [],
      "source": [
        "def translate(sentence):\n",
        "    \"\"\"\n",
        "    :args:\n",
        "        sentence - sentence in Ukrainian (str)\n",
        "    :returns:\n",
        "        translation - sentence in Russian (str)\n",
        "\n",
        "    * find ukrainian embedding for each word in sentence\n",
        "    * transform ukrainian embedding vector\n",
        "    * find nearest russian word and replace\n",
        "    \"\"\"\n",
        "    translation = \"\"\n",
        "    for word in sentence.split():\n",
        "      translation += ru_emb.most_similar(lr.predict(uk_emb[word].reshape(1, -1)))[0][0] + \" \"\n",
        "\n",
        "    return translation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translate(\"1 , 3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "oVNOb3B0KFAZ",
        "outputId": "940a84d5-25e4-442a-a16a-d72d3b41ff6f"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'до , до '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translate(\"кіт зловив мишу\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "F_r_OzPJLDFC",
        "outputId": "ed9a3671-50b4-463d-8bfd-361b9d3dab8a"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'кот поймал мышка '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translate(\"кіт зловив щось\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "tpjdzsDULmGB",
        "outputId": "20decc2a-bbae-4d3e-b7c8-c225fa0aea96"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'кот поймал что-то '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "iiC7RHfxD6u0"
      },
      "outputs": [],
      "source": [
        "assert translate(\"кіт зловив щось\") == \"кот поймал что-то \""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8wihwoiD6u1"
      },
      "source": [
        "Not so bad, right? We can easily improve translation using language model and not one but several nearest neighbours in shared embedding space. But next time."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.4.3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}